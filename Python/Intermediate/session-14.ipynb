{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355b5f03-d2a5-4aa3-a77c-776ccfcb35d5",
   "metadata": {},
   "source": [
    "# Session 14 üêç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45efc9ec-fb9c-458c-b1de-d961145e8449",
   "metadata": {},
   "source": [
    "‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a6ce5-4cd2-45cd-a3b8-9ac277170654",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47542a8-416d-4a3f-8c9d-99781dc53bd8",
   "metadata": {},
   "source": [
    "# 108. NLTK (Natural Language Toolkit)  \n",
    "NLTK is a leading platform for building Python programs to work with human language data (Natural Language Processing). It provides easy-to-use interfaces to over 50 corpora and lexical resources along with a suite of text processing libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35384c2-ea49-4613-b074-ef3b571f756e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4dbbf4-88e4-4a78-b9a0-fd722e1aa1c0",
   "metadata": {},
   "source": [
    "# 109. Text Processing\n",
    "- Tokenization (splitting text into words/sentences)\n",
    "- Stemming (reducing words to root form)\n",
    "- Lemmatization (intelligent word reduction)\n",
    "- Part-of-speech tagging (identifying nouns, verbs etc.)\n",
    "- Named entity recognition (identifying people, places etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb5edf-3034-4d79-8edf-8f0740ea0e27",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5cc52c-9d10-47ad-baeb-0900ab6358ff",
   "metadata": {},
   "source": [
    "# 110. Corpora & Lexical Resources\n",
    "- WordNet (lexical database)\n",
    "- Stopwords (common words to filter out)\n",
    "- Brown Corpus (text categorization)\n",
    "- Gutenberg Corpus (literary works)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2de8aa-11c8-4023-a19b-77faa03c14af",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951e259-8fce-4827-8f9a-0d2d1012d417",
   "metadata": {},
   "source": [
    "# 111. NLP Algorithms\n",
    "- Classification (text categorization)\n",
    "- Clustering (grouping similar documents)\n",
    "- Sentiment analysis (opinion mining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414a2f0-fb76-43e5-bc5f-a92e6bf5ab7b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528c824-0f13-4c5d-aa16-25b5deb65b5f",
   "metadata": {},
   "source": [
    "# 112. Core Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d79214-4d24-4f11-bff3-2a5c092c85e7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49c288-5889-4c9a-971a-26efff710603",
   "metadata": {},
   "source": [
    "## 112-1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6e275-549e-4a1f-9870-85481aa04934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "text = \"Hello world! NLTK is awesome.\"\n",
    "print(word_tokenize(text))  # ['Hello', 'world', '!', 'NLTK', 'is', 'awesome', '.']\n",
    "print(sent_tokenize(text))  # ['Hello world!', 'NLTK is awesome.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15316d1c-0544-472d-b319-3caebcd1bb96",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78187cc-be37-4780-af75-09adb0339955",
   "metadata": {},
   "source": [
    "## 112-2. Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f05167-7cbf-401f-9959-7fd4afbfe766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "words = [\"the\", \"quick\", \"brown\", \"fox\"]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered = [w for w in words if w.lower() not in stop_words]     # ['quick', 'brown', 'fox']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2ee3a-efa5-4cc4-a34a-77e00ce9a9a4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054fd00-b5cb-4760-84ea-8f2798c54d08",
   "metadata": {},
   "source": [
    "## 112-3. Stemming vs Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e58fd4-6968-4ba4-9418-62ea0b1b5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem(\"running\"))  # \"run\"\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"running\", pos=\"v\"))  # \"run\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35849ce-db53-48f1-b820-b6b449c16c3f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2480e08-e095-4ccb-a6a2-dc6c664c7fba",
   "metadata": {},
   "source": [
    "## 112-4. Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c1d0e-788f-4a21-ab58-81d665e83931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "tokens = word_tokenize(\"NLTK is amazing\")\n",
    "print(pos_tag(tokens))  # [('NLTK', 'NNP'), ('is', 'VBZ'), ('amazing', 'VBG')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0063a1-2cac-4bfa-a13f-4cbd6cb3a6bb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb62053-7ce4-4d68-9823-871c17b605f1",
   "metadata": {},
   "source": [
    "## 112-5. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd62a87-e384-4f4c-9447-04739d426360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk\n",
    "\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "tags = pos_tag(word_tokenize(text))\n",
    "entities = ne_chunk(tags)\n",
    "print(entities)  # Shows organizations, locations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09ac45-5e81-447f-b587-98d7369e9afa",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6266616-28d3-4a6b-8338-acbbc49c5d85",
   "metadata": {},
   "source": [
    "## 112-6. Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3458d-4d73-4b4b-a3f4-5f70220c7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "words = word_tokenize(\"hello hello world\")\n",
    "fdist = FreqDist(words)\n",
    "print(fdist.most_common())  # [('hello', 2), ('world', 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c8d7c-6e2d-4726-aa39-9dc00e9fe89e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdac9a4-9085-4539-81d0-609b98b49c87",
   "metadata": {},
   "source": [
    "# 113. Advanced Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d34ed7-9c13-4948-ac9a-bcaad250362e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b8b50-42d5-422f-963a-0fbe8118273e",
   "metadata": {},
   "source": [
    "## 113-1. Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33543d8-2b02-45fa-8364-cf570ffa25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "train_data = [(\"great movie\", \"pos\"), (\"terrible acting\", \"neg\")]\n",
    "classifier = NaiveBayesClassifier.train(train_data)\n",
    "print(classifier.classify(\"awesome film\"))  # \"pos\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015dedb-3cfe-44bb-82ab-3fede36dd451",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0e9ba-5540-4141-b83f-78d5d115876f",
   "metadata": {},
   "source": [
    "## 113-2. WordNet (Lexical Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d4ff6-9b2d-4f69-8136-c7e2e20bab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "synonyms = wordnet.synsets(\"happy\")\n",
    "print(synonyms[0].definition())  # \"enjoying or showing joy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f92119-b568-4820-98a9-e729647ecb0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3fd79-d4de-4f57-bc4a-c1f80b8431d2",
   "metadata": {},
   "source": [
    "## 113-3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3c70a-44a0-4023-9571-88dd418273d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "print(sia.polarity_scores(\"NLTK is amazing!\"))\n",
    "# {'neg': 0.0, 'neu': 0.297, 'pos': 0.703, 'compound': 0.6696}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17049e9a-630a-46cd-8b6c-cf81a6f5cc90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791dc93-9804-44d8-a3e3-fdb759b321a1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40206fb-6731-46dc-9302-0b9bc348b89b",
   "metadata": {},
   "source": [
    "# Some Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d38a8-866c-48a9-a9b5-40df9d99ae4b",
   "metadata": {},
   "source": [
    "**1.**  Tokenize the following text into words and sentences:\n",
    "- \"NLTK is a Python library for NLP. It provides easy-to-use interfaces to over 50 corpora!\"\n",
    "- Remove all stopwords from the tokenized words\n",
    "- Apply both stemming and lemmatization to each remaining word\n",
    "- Compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486b7b8-307c-4eb7-8c14-a1dd72eb2e46",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32b073-bab0-451e-8fd7-a294020f71c6",
   "metadata": {},
   "source": [
    "**2.** Tag parts of speech in the sentence: \"The quick brown fox jumps over the lazy dog\"\n",
    "- Extract only the nouns and verbs from the tagged result\n",
    "- Create a frequency distribution of the POS tags\n",
    "- Visualize the frequency distribution using matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489da9fe-be18-487a-bcc7-e5d6672698ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf117f39-fa94-453e-bca9-2ccd7b507496",
   "metadata": {},
   "source": [
    "**3.**  Process the text: \"Apple Inc. is planning to open a new store in Paris next month\"\n",
    "- Perform named entity recognition\n",
    "- Extract all organization and location entities\n",
    "- Display the entity types and their spans in the original text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e59887-780b-4321-9382-ef4c85ec9684",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32e2d5-3ed7-4865-b63e-21c5cc156f67",
   "metadata": {},
   "source": [
    "**4.**  Find all synsets for the word \"bank\"\n",
    "\n",
    "For each synset, print:\n",
    "- Definition\n",
    "- Example sentences\n",
    "- All lemmas\n",
    "- Calculate the similarity between \"bank\" (financial institution) and \"riverbank\"\n",
    "- Find the lowest common hypernym between \"car\" and \"bicycle\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb22a4-aff7-4377-b09a-a39fa4a3b2a7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17511368-bcb2-4413-87ab-450ca9a64ff2",
   "metadata": {},
   "source": [
    "**5.** Create a small training set of 10 positive and 10 negative movie reviews\n",
    "- Train a Naive Bayes classifier using NLTK\n",
    "- Test it on new sentences like \"The acting was terrible\" and \"Wonderful cinematography\"\n",
    "- Calculate the accuracy using a small test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d682728-1f0e-4594-a1d3-30793e3f0751",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7d348-8fc5-49e9-a3e0-db0d0374a954",
   "metadata": {},
   "source": [
    "**6.** Analyze sentiment of 3 product reviews:\n",
    "\n",
    "    - \"This product is absolutely wonderful!\"\n",
    "\n",
    "    - \"Waste of money, would not recommend\"\n",
    "\n",
    "    - \"It's okay, but could be better\"\n",
    "\n",
    "- For each review, display:\n",
    "\n",
    "    - Polarity scores\n",
    "\n",
    "    - Overall sentiment (positive/negative/neutral)\n",
    "\n",
    "- Compare with TextBlob's sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db6a03-fcd5-4229-aa81-132e3f4cb731",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208864f-ffdb-4b05-b0b1-f6b67683a174",
   "metadata": {},
   "source": [
    "**7.** Take the first 100 words from the NLTK Gutenberg corpus (austen-emma.txt)\n",
    "- Create a frequency distribution\n",
    "- Plot the 10 most common words\n",
    "- Calculate:\n",
    "    - Lexical diversity (unique words/total words)\n",
    "    - Average word length\n",
    "    - Word length distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31370a8b-cd74-4371-9450-8ce4248412e6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bafa50-5d10-40db-97d3-71bdc1821b11",
   "metadata": {},
   "source": [
    "**8.** Create a text processing pipeline that:\n",
    "- Takes raw text input\n",
    "- Tokenizes and removes stopwords\n",
    "- Applies lemmatization\n",
    "- Extracts named entities\n",
    "- Performs sentiment analysis\n",
    "- Apply it to a paragraph from a news article\n",
    "- Present the results in a structured format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3414ed-8ba7-485b-954f-69bb05f37262",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc97f26-cf68-4d50-82a1-ae7dcdfa95ac",
   "metadata": {},
   "source": [
    "#                                                        üåû https://github.com/AI-Planet üåû"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
