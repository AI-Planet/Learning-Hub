{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355b5f03-d2a5-4aa3-a77c-776ccfcb35d5",
   "metadata": {},
   "source": [
    "# Session 21 üêç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45efc9ec-fb9c-458c-b1de-d961145e8449",
   "metadata": {},
   "source": [
    "‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a6ce5-4cd2-45cd-a3b8-9ac277170654",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47542a8-416d-4a3f-8c9d-99781dc53bd8",
   "metadata": {},
   "source": [
    "# 166. Hugging Face Transformers\n",
    "Hugging Face Transformers is a Python library that provides state-of-the-art machine learning models for Natural Language Processing (NLP) and beyond. It offers thousands of pre-trained models for tasks like text classification, question answering, text generation, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35384c2-ea49-4613-b074-ef3b571f756e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4dbbf4-88e4-4a78-b9a0-fd722e1aa1c0",
   "metadata": {},
   "source": [
    "# 167. Important Features\n",
    "- Pre-trained models: Access to models like BERT, GPT-2, RoBERTa, T5, etc.\n",
    "- Easy-to-use APIs: Simple interfaces for common NLP tasks\n",
    "- Model sharing: Access to community-shared models via the Hugging Face Hub\n",
    "- Framework interoperability: Works with PyTorch, TensorFlow, and JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb5edf-3034-4d79-8edf-8f0740ea0e27",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5cc52c-9d10-47ad-baeb-0900ab6358ff",
   "metadata": {},
   "source": [
    "# 168. Core Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2de8aa-11c8-4023-a19b-77faa03c14af",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951e259-8fce-4827-8f9a-0d2d1012d417",
   "metadata": {},
   "source": [
    "## 168-1. Pipeline\n",
    "The simplest way to use pre-trained models is through the pipeline function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2902fb-52c6-4862-9378-a930acdb9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Sentiment analysis\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "result = classifier(\"I love using Hugging Face Transformers!\")\n",
    "print(result)  # [{'label': 'POSITIVE', 'score': 0.9998}]\n",
    "\n",
    "# Text generation\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "result = generator(\"The future of AI is\", max_length=50)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414a2f0-fb76-43e5-bc5f-a92e6bf5ab7b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528c824-0f13-4c5d-aa16-25b5deb65b5f",
   "metadata": {},
   "source": [
    "## 168-2. Auto Classes\n",
    "For more control, use the Auto classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e390a33-4241-4879-8d1c-e61489274e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Process text\n",
    "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d79214-4d24-4f11-bff3-2a5c092c85e7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78187cc-be37-4780-af75-09adb0339955",
   "metadata": {},
   "source": [
    "## 168-3. Tokenizers\n",
    "Tokenizers convert text to model inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e05f1b-864d-4878-8daf-c7ca191680b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize text\n",
    "encoded_input = tokenizer(\"Do not meddle in the affairs of wizards!\", return_tensors=\"pt\")\n",
    "print(encoded_input)\n",
    "# {'input_ids': tensor([[  101,  2079,  2025, 19960,  1999,  1996, 6619,  1997, 12971,   102]]), \n",
    "#  'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), \n",
    "#  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2ee3a-efa5-4cc4-a34a-77e00ce9a9a4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054fd00-b5cb-4760-84ea-8f2798c54d08",
   "metadata": {},
   "source": [
    "## 168-4. Models\n",
    "Different model architectures are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83dc60-4902-4e04-bac9-c85ffd059dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35849ce-db53-48f1-b820-b6b449c16c3f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13dc0b-bbbc-471b-a3d3-cc017ce9e55a",
   "metadata": {},
   "source": [
    "# 169. Common Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ecb54-1af7-4366-99ef-2847acd60eaf",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a44f1-692e-4da9-86ea-7f2afc53dd72",
   "metadata": {},
   "source": [
    "## 169-1. Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7374c-2550-4079-8fa1-864a02512942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "result = classifier(\"This movie is great!\")\n",
    "print(result)  # [{'label': 'POSITIVE', 'score': 0.9998}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32c3b8c-fb2e-4b58-b285-4758c3bda4ae",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94453016-a572-440b-85dd-8b0c73bcca14",
   "metadata": {},
   "source": [
    "## 169-2. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517695c0-0606-44fa-9c70-82fa495e754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "result = ner(\"Hugging Face is a company based in New York City.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35774f0-9e03-4fbb-885d-6ceb387e03e6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a71f69-16c2-48ee-951b-5aba967ddc20",
   "metadata": {},
   "source": [
    "## 169-3. Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761fe801-bbe0-4e89-ac98-9bd8d45e387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "result = qa(\n",
    "    question=\"What is Hugging Face?\",\n",
    "    context=\"Hugging Face is a company that develops tools for NLP.\"\n",
    ")\n",
    "print(result)  # {'answer': 'a company that develops tools for NLP', 'score': 0.7}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcecdb5-706d-4939-91cc-b187bef80e9b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c00b91-6303-404b-9333-b1eb893b09fb",
   "metadata": {},
   "source": [
    "## 169-4. Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516c42a-b2ac-4d44-953f-d41a636dc19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "result = generator(\"In a shocking finding, scientists discovered\", max_length=50)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c32d56-f1b3-4f4d-8381-b80bfd3d43a8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8402fa-654f-4431-be7c-f0f0f6aaad9c",
   "metadata": {},
   "source": [
    "# 170. Fine-Tuning Models\n",
    "A basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c217400-ede2-4f49-8369-ff718bc96400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Prepare model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].select(range(1000)),  # Small subset for demo\n",
    "    eval_dataset=tokenized_datasets[\"test\"].select(range(1000)),\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66851a4e-e878-4f66-a983-046d29d7f74b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba39139b-037b-43c9-aa24-df7dc541ef1b",
   "metadata": {},
   "source": [
    "# 171. Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4055b-eb6f-45da-9176-66bce7bb1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "model.save_pretrained(\"./my_model\")\n",
    "tokenizer.save_pretrained(\"./my_model\")\n",
    "\n",
    "# Load\n",
    "model = AutoModel.from_pretrained(\"./my_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535258be-5cd3-4e28-852d-d4e539b71fc6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aef20a-775f-464b-b30f-56ec6b09b442",
   "metadata": {},
   "source": [
    "# 172. Using the Hugging Face Hub\n",
    "You can share and access models through the Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82252c-fe71-4d74-b064-f5b963177a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Login to upload models\n",
    "notebook_login()\n",
    "\n",
    "# Push to Hub\n",
    "model.push_to_hub(\"my-awesome-model\")\n",
    "tokenizer.push_to_hub(\"my-awesome-model\")\n",
    "\n",
    "# Download from Hub\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"username/my-awesome-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33b0a6-9e4d-440c-8ce1-ba8819628615",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254294a1-de91-4586-adb6-e780f73ce470",
   "metadata": {},
   "source": [
    "# 173. Advanced Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de2de8-84a1-4803-9625-8ca4ea76625d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011bff6d-62a6-4831-9802-6d7813ee3b5a",
   "metadata": {},
   "source": [
    "## 173-1. Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca3070c-c063-4773-b6ba-9b9a2773ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Initialize a custom BERT model\n",
    "config = BertConfig(\n",
    "    hidden_size=768,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=12,\n",
    ")\n",
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53904bae-daba-4e7c-9cd1-07dfc6a82bf0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf55084b-936d-42cd-9c78-0f5acb6cb75a",
   "metadata": {},
   "source": [
    "## 173-2. Mixed Precision Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3abdf-77a7-430d-b495-2855bf67117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    fp16=True,  # Enable mixed precision\n",
    "    # ... other args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b429f7-bf31-4eef-b772-cf9aad85a778",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d8007e-8740-4a76-9a3b-315dc43925e2",
   "metadata": {},
   "source": [
    "## 173-3. Distributed Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb04048-ca37-4e6d-9bec-e03568fbe0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_steps=500,\n",
    "    save_steps=1000,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    logging_dir=\"./logs\",\n",
    "    output_dir=\"./results\",\n",
    "    report_to=\"tensorboard\",\n",
    "    dataloader_num_workers=4,\n",
    "    # For distributed training\n",
    "    local_rank=-1,\n",
    "    deepspeed=\"./ds_config.json\",  # For DeepSpeed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77239165-3fad-46ac-b5a5-e00afb5cfb53",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791dc93-9804-44d8-a3e3-fdb759b321a1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40206fb-6731-46dc-9302-0b9bc348b89b",
   "metadata": {},
   "source": [
    "# Some Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d38a8-866c-48a9-a9b5-40df9d99ae4b",
   "metadata": {},
   "source": [
    "**1.** Use the `pipeline` function to perform sentiment analysis on the following sentences:\n",
    "\n",
    "\"I love coding with Hugging Face!\"\n",
    "\n",
    "\"This movie was terrible and boring.\"\n",
    "\n",
    "\"The weather is okay, I guess.\"\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "A list of dictionaries containing `label` (POSITIVE/NEGATIVE) and `score` (confidence)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486b7b8-307c-4eb7-8c14-a1dd72eb2e46",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32b073-bab0-451e-8fd7-a294020f71c6",
   "metadata": {},
   "source": [
    "**2.** Use the `pipeline` for NER to extract entities from:\n",
    "\n",
    "\"Apple is looking to buy a U.K. startup for $1 billion. Elon Musk is the CEO of Tesla.\"\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "A list of entities with their labels (e.g., `ORG`, `PERSON`, `MONEY`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489da9fe-be18-487a-bcc7-e5d6672698ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf117f39-fa94-453e-bca9-2ccd7b507496",
   "metadata": {},
   "source": [
    "**3.** Use the `text-generation` pipeline with `gpt2` to complete the sentence:\n",
    "\n",
    "\"Artificial intelligence will change the future by\"\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "`max_length=50`\n",
    "\n",
    "`num_return_sequences=2` (generate 2 different completions).\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "Two generated text continuations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e59887-780b-4321-9382-ef4c85ec9684",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32e2d5-3ed7-4865-b63e-21c5cc156f67",
   "metadata": {},
   "source": [
    "**4.** Load `bert-base-uncased` and manually:\n",
    "\n",
    "- Tokenize the sentence: **\"Hugging Face is revolutionizing NLP.\"**\n",
    "\n",
    "- Pass the tokens to the model and extract the last hidden states.\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "Tokenized output (`input_ids`, `attention_mask`).\n",
    "\n",
    "Tensor of shape `(1, sequence_length, 768)` (BERT's hidden states)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb22a4-aff7-4377-b09a-a39fa4a3b2a7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17511368-bcb2-4413-87ab-450ca9a64ff2",
   "metadata": {},
   "source": [
    "**5.** Use `zero-shot-classification` pipeline to classify:\n",
    "\n",
    "\"The new Marvel movie was action-packed and thrilling.\"\n",
    "\n",
    "**Candidate Labels:** `[\"entertainment\", \"politics\", \"sports\", \"technology\"]`\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "Scores for each label (highest for `\"entertainment\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d682728-1f0e-4594-a1d3-30793e3f0751",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7d348-8fc5-49e9-a3e0-db0d0374a954",
   "metadata": {},
   "source": [
    "**6.** Fine-tune `distilbert-base-uncased` on the `emotion` dataset:\n",
    "\n",
    "- Load the dataset: `load_dataset(\"emotion\")`.\n",
    "\n",
    "- Tokenize the data.\n",
    "\n",
    "- Train for **1 epoch** using `Trainer` (simplified setup).\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "Training logs showing loss decreasing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db6a03-fcd5-4229-aa81-132e3f4cb731",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208864f-ffdb-4b05-b0b1-f6b67683a174",
   "metadata": {},
   "source": [
    "**7.** Download and use the `roberta-base-squad2` model for question answering.\n",
    "\n",
    "Ask: **\"What is the capital of France?\"** with context:\n",
    "\n",
    "\"France is a country in Europe. Its capital is Paris.\"\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "`{'answer': 'Paris', 'score': 0.98}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31370a8b-cd74-4371-9450-8ce4248412e6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bafa50-5d10-40db-97d3-71bdc1821b11",
   "metadata": {},
   "source": [
    "**8.** Modify the fine-tuning example to:\n",
    "\n",
    "- Use `TensorFlow` instead of PyTorch.\n",
    "\n",
    "- Manually implement a training loop (without `Trainer`).\n",
    "\n",
    "- Train on a small subset of `imdb` dataset.\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "Validation accuracy improving over epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3414ed-8ba7-485b-954f-69bb05f37262",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc97f26-cf68-4d50-82a1-ae7dcdfa95ac",
   "metadata": {},
   "source": [
    "#                                                        üåû https://github.com/AI-Planet üåû"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
