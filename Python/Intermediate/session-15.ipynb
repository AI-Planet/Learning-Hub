{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355b5f03-d2a5-4aa3-a77c-776ccfcb35d5",
   "metadata": {},
   "source": [
    "# Session 15 üêç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45efc9ec-fb9c-458c-b1de-d961145e8449",
   "metadata": {},
   "source": [
    "‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è‚òÄÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a6ce5-4cd2-45cd-a3b8-9ac277170654",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47542a8-416d-4a3f-8c9d-99781dc53bd8",
   "metadata": {},
   "source": [
    "# 114. Gensim \n",
    "Gensim is a powerful, efficient, and easy-to-use Python library for topic modeling, document similarity analysis, and natural language processing (NLP). It is designed to handle large text collections using streaming and incremental algorithms, making it suitable for big data applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35384c2-ea49-4613-b074-ef3b571f756e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4dbbf4-88e4-4a78-b9a0-fd722e1aa1c0",
   "metadata": {},
   "source": [
    "# 115. Important Features of Gensim\n",
    "- Topic Modeling: Extracts topics from documents using algorithms like Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA/LSI), and Hierarchical Dirichlet Process (HDP).\n",
    "- Word Embeddings: Implements Word2Vec, FastText, and Doc2Vec for word and document vector representations.\n",
    "- Document Similarity: Computes similarity between documents using TF-IDF, BM25, and Word Mover‚Äôs Distance (WMD).\n",
    "- Efficient & Scalable: Works well with large datasets using memory-efficient streaming.\n",
    "- Preprocessing Tools: Includes tokenization, stopword removal, and lemmatization support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb5edf-3034-4d79-8edf-8f0740ea0e27",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5cc52c-9d10-47ad-baeb-0900ab6358ff",
   "metadata": {},
   "source": [
    "# 116. Core Components & Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2de8aa-11c8-4023-a19b-77faa03c14af",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951e259-8fce-4827-8f9a-0d2d1012d417",
   "metadata": {},
   "source": [
    "## 116-1. Preprocessing Text\n",
    "Gensim provides tools to clean and prepare text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8febed-3dfe-4a6c-9d0b-52fd6f4e0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "\n",
    "text = \"Gensim is a powerful library for NLP and topic modeling.\"\n",
    "\n",
    "# Tokenization & lowercase conversion\n",
    "tokens = simple_preprocess(text)\n",
    "print(tokens)  # Output: ['gensim', 'powerful', 'library', 'for', 'nlp', 'and', 'topic', 'modeling']\n",
    "\n",
    "# Remove stopwords\n",
    "filtered_text = remove_stopwords(text)\n",
    "print(filtered_text)  # Output: \"Gensim powerful library NLP topic modeling.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414a2f0-fb76-43e5-bc5f-a92e6bf5ab7b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528c824-0f13-4c5d-aa16-25b5deb65b5f",
   "metadata": {},
   "source": [
    "## 116-2. Creating a Dictionary & Corpus\n",
    "Before topic modeling, we convert text into numerical representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201cc47-b30e-4481-89f3-130b52915eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "documents = [\n",
    "    \"Gensim is great for NLP tasks.\",\n",
    "    \"Topic modeling is useful for text analysis.\",\n",
    "    \"Gensim supports Word2Vec and LDA.\"\n",
    "]\n",
    "\n",
    "# Tokenize and create a dictionary\n",
    "tokenized_docs = [simple_preprocess(doc) for doc in documents]\n",
    "dictionary = corpora.Dictionary(tokenized_docs)\n",
    "\n",
    "# Create a Bag-of-Words (BoW) corpus\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "print(\"Dictionary:\", dictionary.token2id)\n",
    "print(\"Corpus (BoW):\", corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816aeca-2931-44bb-9839-c009e1dc2c52",
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8ac2990-fa2f-46f7-8eb8-52e4bf750c60",
   "metadata": {},
   "source": [
    "Dictionary: {'analysis': 0, 'for': 1, 'is': 2, 'modeling': 3, 'text': 4, 'topic': 5, 'useful': 6, 'and': 7, 'gensim': 8, 'great': 9, 'lda': 10, 'nlp': 11, 'supports': 12, 'tasks': 13, 'word2vec': 14}\n",
    "Corpus (BoW): [[(8, 1), (9, 1), (1, 1), (2, 1), (11, 1), (13, 1)], [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(7, 1), (8, 1), (10, 1), (12, 1), (14, 1)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d79214-4d24-4f11-bff3-2a5c092c85e7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49c288-5889-4c9a-971a-26efff710603",
   "metadata": {},
   "source": [
    "## 116-3. Topic Modeling with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6e275-549e-4a1f-9870-85481aa04934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "# Train LDA model\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=2,\n",
    "    random_state=42,\n",
    "    passes=10\n",
    ")\n",
    "\n",
    "# Print topics\n",
    "print(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33446027-ddd4-4ca0-bb6b-b13166364724",
   "metadata": {},
   "source": [
    "**output:**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6d10f6b-4946-44e0-a1fc-4b0da1046821",
   "metadata": {},
   "source": [
    "[\n",
    "  (0, '0.086*\"gensim\" + 0.086*\"word2vec\" + 0.086*\"lda\" + 0.086*\"supports\" + 0.086*\"and\"'),\n",
    "  (1, '0.118*\"topic\" + 0.118*\"modeling\" + 0.118*\"useful\" + 0.118*\"text\" + 0.118*\"for\"')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15316d1c-0544-472d-b319-3caebcd1bb96",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78187cc-be37-4780-af75-09adb0339955",
   "metadata": {},
   "source": [
    "## 116-4. Word Embeddings with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f05167-7cbf-401f-9959-7fd4afbfe766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [\n",
    "    [\"gensim\", \"is\", \"great\", \"for\", \"NLP\"],\n",
    "    [\"word2vec\", \"is\", \"used\", \"for\", \"embeddings\"],\n",
    "    [\"topic\", \"modeling\", \"is\", \"useful\"]\n",
    "]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Find similar words\n",
    "similar_words = model.wv.most_similar(\"gensim\")\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d4c34-5ac4-4a5c-ab81-02e1f5b2fecd",
   "metadata": {},
   "source": [
    "**output:**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89b338e7-a580-486b-afbf-2e1f213336b2",
   "metadata": {},
   "source": [
    "[('great', 0.987), ('NLP', 0.956), ('is', 0.932), ('word2vec', 0.876), ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2ee3a-efa5-4cc4-a34a-77e00ce9a9a4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054fd00-b5cb-4760-84ea-8f2798c54d08",
   "metadata": {},
   "source": [
    "## 116-5. Document Similarity with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e58fd4-6968-4ba4-9418-62ea0b1b5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.similarities import SparseMatrixSimilarity\n",
    "\n",
    "# Train TF-IDF model\n",
    "tfidf = TfidfModel(corpus)\n",
    "\n",
    "# Convert corpus to TF-IDF vectors\n",
    "tfidf_corpus = tfidf[corpus]\n",
    "\n",
    "# Index for similarity search\n",
    "index = SparseMatrixSimilarity(tfidf_corpus, num_features=len(dictionary))\n",
    "\n",
    "# Query a new document\n",
    "query = \"NLP and topic modeling\"\n",
    "query_bow = dictionary.doc2bow(simple_preprocess(query))\n",
    "query_tfidf = tfidf[query_bow]\n",
    "\n",
    "# Find similar documents\n",
    "similarities = index[query_tfidf]\n",
    "print(list(enumerate(similarities)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca0396-9d1b-47bc-a825-d5c717a2cfca",
   "metadata": {},
   "source": [
    "**output:**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe7ba791-2793-474c-987b-005497bf25e5",
   "metadata": {},
   "source": [
    "[(0, 0.789), (1, 0.456), (2, 0.321)]  # (doc_index, similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35849ce-db53-48f1-b820-b6b449c16c3f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0238df-87eb-42b4-80e5-3d704029734f",
   "metadata": {},
   "source": [
    "# 117. Real-World Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de71c7-fd8b-4daf-81af-97a811e8923b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13dc0b-bbbc-471b-a3d3-cc017ce9e55a",
   "metadata": {},
   "source": [
    "## 117-1. News Article Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3620f-9ee9-43b4-9818-1193ff8f8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA on news dataset\n",
    "# Assign topics to new articles\n",
    "new_doc = [\"economy\", \"grows\", \"5%\"]\n",
    "new_bow = dictionary.doc2bow(new_doc)\n",
    "topics = lda[new_bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ecb54-1af7-4366-99ef-2847acd60eaf",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a44f1-692e-4da9-86ea-7f2afc53dd72",
   "metadata": {},
   "source": [
    "## 117-2. Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7374c-2550-4079-8fa1-864a02512942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Doc2Vec to find similar products\n",
    "model = Doc2Vec(product_descriptions)\n",
    "sims = model.dv.most_similar(\"iphone 13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32c3b8c-fb2e-4b58-b285-4758c3bda4ae",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94453016-a572-440b-85dd-8b0c73bcca14",
   "metadata": {},
   "source": [
    "# 118. Advanced Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35774f0-9e03-4fbb-885d-6ceb387e03e6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a71f69-16c2-48ee-951b-5aba967ddc20",
   "metadata": {},
   "source": [
    "## 118-1. Streaming Large Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3faad0-e589-43ad-a4da-f772bb84c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import WikiCorpus\n",
    "\n",
    "wiki = WikiCorpus(\"enwiki-latest-pages-articles.xml.bz2\", lemmatize=False)\n",
    "for text in wiki.get_texts():\n",
    "    process(text)  # Processes one article at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3343c7e-43b2-4a70-88f3-fa724d3129da",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c00b91-6303-404b-9333-b1eb893b09fb",
   "metadata": {},
   "source": [
    "## 118-2. Distributed Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12a104-388c-413f-a959-3be2dc0b8bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "model = Word2Vec(sentences, workers=cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c32d56-f1b3-4f4d-8381-b80bfd3d43a8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acc4f4-a309-4f97-97aa-fc9e047b64ca",
   "metadata": {},
   "source": [
    "# 119. Optimization & Performance Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc657257-2b51-40de-85f4-b03ccc99b254",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8402fa-654f-4431-be7c-f0f0f6aaad9c",
   "metadata": {},
   "source": [
    "## 119-1. Memory Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da047fd2-c80e-4bfa-9abd-58cc6afe0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save memory by streaming corpus\n",
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        for line in open('bigdata.txt'):\n",
    "            yield simple_preprocess(line)\n",
    "\n",
    "corpus = MyCorpus()  # Doesn‚Äôt load full data into RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66851a4e-e878-4f66-a983-046d29d7f74b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca0e092-e0ad-4cda-9916-3f14344f04e3",
   "metadata": {},
   "source": [
    "## 119-2. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb789ad-0ee6-4a8d-a048-7afea599b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherence = CoherenceModel(\n",
    "    model=lda,\n",
    "    texts=docs,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ")\n",
    "print(coherence.get_coherence())  # Higher = Better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307dd3a-7b26-4eff-a803-331439aa418b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba39139b-037b-43c9-aa24-df7dc541ef1b",
   "metadata": {},
   "source": [
    "# 120. Troubleshooting & Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535258be-5cd3-4e28-852d-d4e539b71fc6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c22f321-a591-4b25-9988-56abe3eef424",
   "metadata": {},
   "source": [
    "## 120-1. Common Issues"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9edd13e-9e6f-48f2-9ea2-62909a7ac827",
   "metadata": {},
   "source": [
    "Problem: Training LDA is slow\n",
    "Fix: Reduce passes, use workers for multicore.\n",
    "\n",
    "Problem: MemoryError on large datasets\n",
    "Fix: Use streaming (iter), save intermediate files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ef2dc-3922-436c-95f9-72ae52279873",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aef20a-775f-464b-b30f-56ec6b09b442",
   "metadata": {},
   "source": [
    "## 120-2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae222a-230a-403d-8426-46792c303b62",
   "metadata": {},
   "source": [
    "|Model\t|Key Parameters\t|Typical Values|\n",
    "|-------|---------------|--------------|\n",
    "|LDA\t|num_topics, passes\t|10-100, 10-50|\n",
    "|Word2Vec\t|vector_size, window\t|100-300, 5-10|\n",
    "|FastText\t|min_n, max_n (ngrams)\t|3, 6|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea3d71-40cd-4876-80f3-17c87247848b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791dc93-9804-44d8-a3e3-fdb759b321a1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40206fb-6731-46dc-9302-0b9bc348b89b",
   "metadata": {},
   "source": [
    "# Some Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d38a8-866c-48a9-a9b5-40df9d99ae4b",
   "metadata": {},
   "source": [
    "**1.**  Clean and tokenize raw text data\n",
    "- Remove punctuation and stopwords\n",
    "- Apply lemmatization (use pattern or spaCy integration)\n",
    "- Detect and merge bigrams automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486b7b8-307c-4eb7-8c14-a1dd72eb2e46",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32b073-bab0-451e-8fd7-a294020f71c6",
   "metadata": {},
   "source": [
    "**2.** Handle a large text file without loading into RAM\n",
    "- Implement a Python generator that yields one preprocessed document at a time\n",
    "- Build a dictionary from the streaming corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489da9fe-be18-487a-bcc7-e5d6672698ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf117f39-fa94-453e-bca9-2ccd7b507496",
   "metadata": {},
   "source": [
    "**3.**  Discover hidden topics in news articles\n",
    "- Train an LDA model on 20 Newsgroups dataset\n",
    "- Compute topic coherence score (c_v)\n",
    "- Visualize topics with pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e59887-780b-4321-9382-ef4c85ec9684",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32e2d5-3ed7-4865-b63e-21c5cc156f67",
   "metadata": {},
   "source": [
    "**4.**  Train and evaluate word embeddings\n",
    "- Train Skip-gram and CBOW models on Wikipedia text\n",
    "- Find most similar words to \"algorithm\"\n",
    "- Solve analogies: \"king - man + woman = ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb22a4-aff7-4377-b09a-a39fa4a3b2a7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17511368-bcb2-4413-87ab-450ca9a64ff2",
   "metadata": {},
   "source": [
    "**5.** Build a news article recommender\n",
    "- Convert articles to TF-IDF vectors\n",
    "- Implement similarity search using SparseMatrixSimilarity\n",
    "- Query with \"climate change policy\" and return top 3 matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d682728-1f0e-4594-a1d3-30793e3f0751",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7d348-8fc5-49e9-a3e0-db0d0374a954",
   "metadata": {},
   "source": [
    "**6.** Scale training across CPU cores\n",
    "- Configure Word2Vec to use all available CPU cores\n",
    "- Monitor memory usage during training\n",
    "- Compare speed vs single-core training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db6a03-fcd5-4229-aa81-132e3f4cb731",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208864f-ffdb-4b05-b0b1-f6b67683a174",
   "metadata": {},
   "source": [
    "**7.** Tune hyperparameters for best results\n",
    "- Grid search over num_topics (5,10,20) and passes (5,10,20)\n",
    "- Evaluate using topic coherence scores\n",
    "- Implement memory-efficient online LDA (update_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31370a8b-cd74-4371-9450-8ce4248412e6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bafa50-5d10-40db-97d3-71bdc1821b11",
   "metadata": {},
   "source": [
    "**8.** Create a Flask endpoint for topic prediction\n",
    "- Save trained LDA model to disk\n",
    "- Build a Flask API that:\n",
    "- Accepts raw text input\n",
    "- Returns predicted topics\n",
    "- Test with cURL/POSTMAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3414ed-8ba7-485b-954f-69bb05f37262",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc97f26-cf68-4d50-82a1-ae7dcdfa95ac",
   "metadata": {},
   "source": [
    "#                                                        üåû https://github.com/AI-Planet üåû"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
