{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355b5f03-d2a5-4aa3-a77c-776ccfcb35d5",
   "metadata": {},
   "source": [
    "# Session 19 ðŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45efc9ec-fb9c-458c-b1de-d961145e8449",
   "metadata": {},
   "source": [
    "â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸â˜€ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a6ce5-4cd2-45cd-a3b8-9ac277170654",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47542a8-416d-4a3f-8c9d-99781dc53bd8",
   "metadata": {},
   "source": [
    "# 150. Dask \n",
    "Dask is a flexible parallel computing library in Python that integrates with the PyData ecosystem (NumPy, Pandas, Scikit-learn) to enable scalable and efficient computation on datasets that don't fit into memory. It provides dynamic task scheduling and parallel execution, making it ideal for big data processing, machine learning, and scientific computing.\n",
    "\n",
    "Dask is designed to:\n",
    "- Scale Python workflows from a single machine to distributed clusters.\n",
    "- Mimic familiar APIs (like Pandas, NumPy) for seamless adoption.\n",
    "- Handle larger-than-memory datasets efficiently using lazy evaluation and chunking.\n",
    "- Work with existing tools (e.g., NumPy, Pandas, Scikit-learn, XGBoost)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35384c2-ea49-4613-b074-ef3b571f756e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4dbbf4-88e4-4a78-b9a0-fd722e1aa1c0",
   "metadata": {},
   "source": [
    "# 151. Important Features\n",
    "- Parallel Computing: Automatically splits tasks across CPU cores.\n",
    "- Lazy Evaluation: Computations are deferred until explicitly requested.\n",
    "- Out-of-Core Processing: Works with datasets larger than RAM.\n",
    "- Distributed Computing: Scales to clusters (using dask.distributed).\n",
    "- Integration: Works with Pandas, NumPy, Scikit-learn, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb5edf-3034-4d79-8edf-8f0740ea0e27",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5cc52c-9d10-47ad-baeb-0900ab6358ff",
   "metadata": {},
   "source": [
    "# 152. Dask Components\n",
    "Dask provides different high-level collections and low-level schedulers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2de8aa-11c8-4023-a19b-77faa03c14af",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951e259-8fce-4827-8f9a-0d2d1012d417",
   "metadata": {},
   "source": [
    "## 152-1. High-Level Collections\n",
    "\n",
    "- `dask.array`:\tParallel NumPy arrays\n",
    "- `dask.dataframe`:\tParallel Pandas DataFrames\n",
    "- `dask.bag`: Parallel list-like operations\n",
    "- `dask.delayed`: Custom task parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414a2f0-fb76-43e5-bc5f-a92e6bf5ab7b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528c824-0f13-4c5d-aa16-25b5deb65b5f",
   "metadata": {},
   "source": [
    "## 152-2. Low-Level Schedulers\n",
    "- `Single-machine scheduler` (default, multi-threaded/multi-process).\n",
    "- `Distributed scheduler` (dask.distributed) for clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d79214-4d24-4f11-bff3-2a5c092c85e7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78187cc-be37-4780-af75-09adb0339955",
   "metadata": {},
   "source": [
    "# 153. Dask in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2ee3a-efa5-4cc4-a34a-77e00ce9a9a4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054fd00-b5cb-4760-84ea-8f2798c54d08",
   "metadata": {},
   "source": [
    "## 153-1. Dask Arrays (dask.array)\n",
    "Chunked NumPy arrays processed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e58fd4-6968-4ba4-9418-62ea0b1b5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "# Create a large random array (split into chunks)\n",
    "x = da.random.random((10000, 10000), chunks=(1000, 1000))\n",
    "\n",
    "# Compute mean (lazy evaluation)\n",
    "mean = x.mean()\n",
    "mean.compute()  # Triggers actual computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35849ce-db53-48f1-b820-b6b449c16c3f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13dc0b-bbbc-471b-a3d3-cc017ce9e55a",
   "metadata": {},
   "source": [
    "## 153-2. Dask DataFrames (dask.dataframe)\n",
    "Larger-than-memory Pandas DataFrames with the same API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3620f-9ee9-43b4-9818-1193ff8f8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Read a large CSV in chunks\n",
    "df = dd.read_csv(\"large_dataset.csv\", blocksize=25e6)  # 25MB chunks\n",
    "\n",
    "# Groupby and aggregate (lazy)\n",
    "result = df.groupby(\"category\").price.mean()\n",
    "result.compute()  # Executes the computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ecb54-1af7-4366-99ef-2847acd60eaf",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a44f1-692e-4da9-86ea-7f2afc53dd72",
   "metadata": {},
   "source": [
    "## 153-3. Dask Bags (dask.bag)\n",
    "Parallel processing of semi-structured data (JSON, logs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7374c-2550-4079-8fa1-864a02512942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "\n",
    "# Process JSON lines in parallel\n",
    "bag = db.read_text(\"logs.jsonl\").map(json.loads)\n",
    "filtered = bag.filter(lambda x: x[\"error\"]).pluck(\"message\")\n",
    "filtered.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32c3b8c-fb2e-4b58-b285-4758c3bda4ae",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94453016-a572-440b-85dd-8b0c73bcca14",
   "metadata": {},
   "source": [
    "## 153-4. Dask Delayed (dask.delayed)\n",
    "Parallelize custom functions with minimal changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517695c0-0606-44fa-9c70-82fa495e754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "\n",
    "@delayed\n",
    "def slow_function(x):\n",
    "    return x * 2\n",
    "\n",
    "results = [slow_function(i) for i in range(10)]\n",
    "dask.compute(*results)  # Runs in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35774f0-9e03-4fbb-885d-6ceb387e03e6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a71f69-16c2-48ee-951b-5aba967ddc20",
   "metadata": {},
   "source": [
    "# 154. Dask Distributed (Scaling to Clusters)\n",
    "Dask can run on distributed systems (e.g., Kubernetes, HPC, cloud clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcecdb5-706d-4939-91cc-b187bef80e9b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c00b91-6303-404b-9333-b1eb893b09fb",
   "metadata": {},
   "source": [
    "## 154-1. Local Cluster (Multi-core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12a104-388c-413f-a959-3be2dc0b8bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()  # Starts a local multi-worker cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c32d56-f1b3-4f4d-8381-b80bfd3d43a8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8402fa-654f-4431-be7c-f0f0f6aaad9c",
   "metadata": {},
   "source": [
    "## 154-2. Scaling to a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da047fd2-c80e-4bfa-9abd-58cc6afe0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# Connect to a remote cluster (e.g., Kubernetes, SLURM, YARN)\n",
    "client = Client(\"scheduler-address:8786\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66851a4e-e878-4f66-a983-046d29d7f74b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba39139b-037b-43c9-aa24-df7dc541ef1b",
   "metadata": {},
   "source": [
    "## 154-3. Dask Dashboard\n",
    "Real-time monitoring at http://localhost:8787 (if using Client())."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535258be-5cd3-4e28-852d-d4e539b71fc6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c22f321-a591-4b25-9988-56abe3eef424",
   "metadata": {},
   "source": [
    "# 155. When to Use Dask?\n",
    "- Your data is too big for Pandas/NumPy but fits on a single machine.\n",
    "- You need parallel processing without rewriting code.\n",
    "- You want to scale from a laptop to a cluster seamlessly.\n",
    "- You work with machine learning pipelines (Dask-ML)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ef2dc-3922-436c-95f9-72ae52279873",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aef20a-775f-464b-b30f-56ec6b09b442",
   "metadata": {},
   "source": [
    "# 156. Limitations\n",
    "- Not as fast as Spark for very large distributed data (but easier to use).\n",
    "- Overhead for small datasets (use Pandas/NumPy if data fits in RAM).\n",
    "- Some Pandas operations not fully optimized yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33b0a6-9e4d-440c-8ce1-ba8819628615",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791dc93-9804-44d8-a3e3-fdb759b321a1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40206fb-6731-46dc-9302-0b9bc348b89b",
   "metadata": {},
   "source": [
    "# Some Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d38a8-866c-48a9-a9b5-40df9d99ae4b",
   "metadata": {},
   "source": [
    "**1.** Create a large random dask.array (shape (5000, 5000), chunked into (1000, 1000)).\n",
    "\n",
    "Compute the mean, standard deviation, and sum.\n",
    "\n",
    "Compare execution time with NumPy (%timeit in Jupyter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486b7b8-307c-4eb7-8c14-a1dd72eb2e46",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32b073-bab0-451e-8fd7-a294020f71c6",
   "metadata": {},
   "source": [
    "**2.** Load a CSV file (e.g., sample data) using dask.dataframe.\n",
    "\n",
    "Filter rows where a column (e.g., value > 0).\n",
    "\n",
    "Group by a categorical column and compute aggregations (mean, max)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489da9fe-be18-487a-bcc7-e5d6672698ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf117f39-fa94-453e-bca9-2ccd7b507496",
   "metadata": {},
   "source": [
    "**3.** Read a JSON file (or multiline JSON) using dask.bag.\n",
    "\n",
    "Extract a field (e.g., user_id).\n",
    "\n",
    "Count occurrences of a value (e.g., error_type)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e59887-780b-4321-9382-ef4c85ec9684",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32e2d5-3ed7-4865-b63e-21c5cc156f67",
   "metadata": {},
   "source": [
    "**4.** Create 3 functions (@delayed) that simulate slow tasks (e.g., time.sleep(1)).\n",
    "\n",
    "Chain them in a workflow (e.g., task3(task2(task1(x)))).\n",
    "\n",
    "Compute in parallel and compare runtime vs. sequential execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb22a4-aff7-4377-b09a-a39fa4a3b2a7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17511368-bcb2-4413-87ab-450ca9a64ff2",
   "metadata": {},
   "source": [
    "**5.** Initialize a local Client() with 4 workers.\n",
    "\n",
    "Run a Dask DataFrame operation (e.g., groupby().mean()).\n",
    "\n",
    "Monitor progress in the Dask Dashboard (http://localhost:8787)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d682728-1f0e-4594-a1d3-30793e3f0751",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7d348-8fc5-49e9-a3e0-db0d0374a954",
   "metadata": {},
   "source": [
    "**6.** Deploy a temporary Dask cluster (e.g., using dask-cloudprovider or LocalCluster).\n",
    "\n",
    "Submit a parallel job (e.g., processing multiple files).\n",
    "\n",
    "Verify worker logs in the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db6a03-fcd5-4229-aa81-132e3f4cb731",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208864f-ffdb-4b05-b0b1-f6b67683a174",
   "metadata": {},
   "source": [
    "**7.** Train a Scikit-learn model (e.g., RandomForestRegressor) on a large dataset using dask_ml.\n",
    "\n",
    "Compare training time with/without Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31370a8b-cd74-4371-9450-8ce4248412e6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bafa50-5d10-40db-97d3-71bdc1821b11",
   "metadata": {},
   "source": [
    "**8.** Benchmark Dask vs. Pandas on a small dataset (<1GB).\n",
    "\n",
    "Identify operations where Pandas outperforms Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3414ed-8ba7-485b-954f-69bb05f37262",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc97f26-cf68-4d50-82a1-ae7dcdfa95ac",
   "metadata": {},
   "source": [
    "#                                                        ðŸŒž https://github.com/AI-Planet ðŸŒž"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
